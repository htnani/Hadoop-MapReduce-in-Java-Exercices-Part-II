{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código desenvolvido em Java para criação da aplicação que utilize a base de dados compras.txt e lista a soma de cada produto vendido por cidade. Projeto inicial chamado somacidadeproduto contendo a estrutura-base das classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-Desenvolvimento das 3 classes Mapper, Reducer e Driver para implementação da aplicação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Desenvolvimento da classe Driver SomaCidadeProdutoDriver.java\n",
    "\n",
    "import org.apache.hadoop.conf.Configuration;\n",
    "import org.apache.hadoop.fs.Path;\n",
    "import org.apache.hadoop.io.FloatWritable;\n",
    "import org.apache.hadoop.io.Text;\n",
    "import org.apache.hadoop.mapreduce.Job;\n",
    "import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\n",
    "import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\n",
    "\n",
    "public class SomaCidadeProdutoDriver {\n",
    "\n",
    "\tpublic static void main(String[] args) throws Exception {\n",
    "\n",
    "\t\tConfiguration conf = new Configuration();\n",
    "\t\tJob job = Job.getInstance(conf, \"somacidadeprodutodriver\");\n",
    "\t\tjob.setJarByClass(SomaCidadeProdutoDriver.class);\n",
    "\t\tjob.setMapperClass(SomaCidadeProdutoMapper.class);\n",
    "\t\tjob.setMapOutputKeyClass(Text.class);\n",
    "\t\tjob.setMapOutputValueClass(FloatWritable.class);\n",
    "\t\tjob.setReducerClass(SomaCidadeProdutoReducer.class);\n",
    "\t\tjob.setOutputKeyClass(Text.class);\n",
    "\t\tjob.setOutputValueClass(FloatWritable.class);\n",
    "\t\tFileInputFormat.addInputPath(job, new Path(args[0]));\n",
    "\t\tFileOutputFormat.setOutputPath(job, new Path(args[1]));\n",
    "\t\tSystem.exit(job.waitForCompletion(true) ? 0 : 1);\n",
    "\n",
    "\t}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Desenvolvimento da classe Mapper SomaCidadeProdutoMapper.java\n",
    "\n",
    "import java.io.IOException;\n",
    "import org.apache.hadoop.io.FloatWritable;\n",
    "import org.apache.hadoop.io.Text;\n",
    "import org.apache.hadoop.mapreduce.Mapper;\n",
    "\n",
    "public class SomaCidadeProdutoMapper extends Mapper<Object, Text, Text, FloatWritable> {\n",
    "\n",
    "\tprivate final static FloatWritable valor = new FloatWritable(0);\n",
    "\tprivate final static Text cidadeproduto = new Text();\n",
    "\n",
    "\tpublic void map(Object key, Text value, Context context) throws IOException, InterruptedException {\n",
    "\t\t\n",
    "\t\tString[] linha=value.toString().split(\";\");\t\t\n",
    "\t\tcidadeproduto.set(linha[2] +\" \"+linha[3]);\n",
    "\t\tvalor.set(Float.parseFloat(linha[4].replaceAll(\":\", \".\")));\t\n",
    "\t\tcontext.write(cidadeproduto, valor);\t\t\n",
    "\t}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Desesenvolvimento da classe Reducer SomaCidadeProdutoReducer.java\n",
    "\n",
    "import java.io.IOException;\n",
    "import org.apache.hadoop.io.FloatWritable;\n",
    "import org.apache.hadoop.io.Text;\n",
    "import org.apache.hadoop.mapreduce.Reducer;\n",
    "\n",
    "public class SomaCidadeProdutoReducer extends\tReducer<Text, FloatWritable, Text, FloatWritable> {\n",
    "\t\n",
    "\tpublic void reduce(Text key, Iterable<FloatWritable> values, Context context) throws IOException, InterruptedException {\n",
    "\t\tlong sumValue = 0;\n",
    "\t\t\n",
    "\t\tfor (FloatWritable value : values) {\n",
    "\t\t\tsumValue += value.get();\n",
    "\t\t}\n",
    "\t\tcontext.write(key, new FloatWritable(sumValue));\n",
    "\t}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-Geração do arquivo JAR da aplicação e definição do path:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo: /home/cloudera/Documents/somacidadeproduto.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-Execução do job JAR no ambiente Hadoop e consumo do arquivo bases/compras.txt já armazenado no HDFS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hadoop jar ~/Documents/somacidadeproduto.jar SomaCidadeProdutoDriver bases/compras.txt saida/cidade_produto_soma"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "SciJava",
   "language": "groovy",
   "name": "scijava"
  },
  "language_info": {
   "codemirror_mode": "groovy",
   "file_extension": "",
   "mimetype": "",
   "name": "scijava",
   "nbconverter_exporter": "",
   "pygments_lexer": "groovy",
   "version": "1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
