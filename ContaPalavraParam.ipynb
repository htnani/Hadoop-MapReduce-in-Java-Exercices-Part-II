{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código desenvolvido em Java para criação da aplicação que faz a contagem de hashtags somente de uma determina palavra indicada pelo usuário como parâmetro. Também deleta a pasta destino passada como parametro em caso de a mesma existir. Projeto inicial chamado contapalavraparam contendo a estrutura-base das classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-Desenvolvimento das 3 classes Mapper, Reducer e Driver para implementação da aplicação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Desenvolvimento da classe Driver ContaPalavraParamDriver.java\n",
    "\n",
    "import java.io.IOException;\n",
    "import org.apache.hadoop.conf.Configuration;\n",
    "import org.apache.hadoop.fs.FileSystem;\n",
    "import org.apache.hadoop.fs.Path;\n",
    "import org.apache.hadoop.io.IntWritable;\n",
    "import org.apache.hadoop.io.Text;\n",
    "import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\n",
    "import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\n",
    "import org.apache.hadoop.mapreduce.Job;\n",
    "\n",
    "public class ContaPalavraParamDriver {\n",
    "\tpublic static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException{\n",
    "\t\tConfiguration conf = new Configuration();\n",
    "\t\t//recebendo o parametro palavra do usuario\n",
    "\t\tconf.set(\"palavra\",args[2]);\n",
    "\t\t\n",
    "\t\t//verifica se a pasta destino já existe, se sim, a pasta será excluida\n",
    "\t\tconf.set(\"fs.defaultFS\",\"hdfs://localhost:8020/\");\n",
    "\t\tFileSystem dfs = FileSystem.get(conf);\n",
    "\t\tString nomeDir = args[1];\n",
    "\t\tPath caminhoDir = new Path(dfs.getWorkingDirectory()+\"/\"+nomeDir);\n",
    "\t\t\n",
    "\t\tif(dfs.exists(caminhoDir)){\n",
    "\t\t\tSystem.out.println(\"Pasta destino já existe e será excluida\");\n",
    "\t\t\tdfs.delete(caminhoDir);\n",
    "\t\t}\n",
    "\n",
    "\t\tJob job = Job.getInstance(conf);\n",
    "\t\tjob.setJarByClass(ContaPalavraParamDriver.class);\n",
    "\t\tjob.setMapperClass(ContaPalavraParamMapper.class);\n",
    "\t\tjob.setReducerClass(ContaPalavraParamReducer.class);\n",
    "\t\tjob.setOutputKeyClass(Text.class);\n",
    "\t\tjob.setOutputValueClass(IntWritable.class);\n",
    "\t\tjob.setNumReduceTasks(1);\n",
    "\n",
    "\t\tFileInputFormat.addInputPath(job, new Path(args[0]));\n",
    "\t\tFileOutputFormat.setOutputPath(job, new Path(args[1]));\t\t\n",
    "\t\tSystem.exit(job.waitForCompletion(true) ? 0 : 1);\n",
    "\t}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Desenvolvimento da classe Mapper ContaPalavraParamMapper.java\n",
    "\n",
    "import java.io.IOException;\n",
    "import java.util.StringTokenizer;\n",
    "import org.apache.hadoop.conf.Configuration;\n",
    "import org.apache.hadoop.io.IntWritable;\n",
    "import org.apache.hadoop.io.Text;\n",
    "import org.apache.hadoop.mapreduce.Mapper;\n",
    "\n",
    "public class ContaPalavraParamMapper extends Mapper<Object, Text, Text, IntWritable> {\n",
    "\n",
    "\tprivate final static IntWritable numeroum = new IntWritable(1);\n",
    "\n",
    "\tpublic void map(Object key, Text value, Context context) throws IOException, InterruptedException {\n",
    "\t\t//capturando o parametro palavra informado pelo usuario\n",
    "\t\tConfiguration conf = context.getConfiguration();\n",
    "\t\tString palavra = conf.get(\"palavra\").toString().toLowerCase();\n",
    "\t\t\n",
    "\t\tStringTokenizer itr = new StringTokenizer(value.toString().replaceAll(\"[^a-zA-Z ]\", \"\").toLowerCase());\n",
    "\t\twhile (itr.hasMoreTokens()) {\n",
    "\t\t\tString itr1 = itr.nextToken();\n",
    "\t\t\tif(itr1.equals(palavra)){\n",
    "\t\t\t\tcontext.write(new Text(itr1), numeroum);\n",
    "\t\t\t}\n",
    "\t\t\t\n",
    "\t\t}\n",
    "\t}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Desesenvolvimento da classe Reducer ContaPalavraParamReducer.java\n",
    "\n",
    "import java.io.IOException;\n",
    "import org.apache.hadoop.io.IntWritable;\n",
    "import org.apache.hadoop.io.Text;\n",
    "import org.apache.hadoop.mapreduce.Reducer;\n",
    "\n",
    "public class ContaPalavraParamReducer extends\n",
    "\t\tReducer<Text, IntWritable, Text, IntWritable> {\n",
    "\n",
    "\tpublic void reduce(Text key, Iterable<IntWritable> values, Context context)\n",
    "\t\t\tthrows IOException, InterruptedException {\n",
    "\t\tint soma = 0;\n",
    "\t\tfor (IntWritable val : values) {\n",
    "\t\t\tsoma += val.get();\n",
    "\t\t}\n",
    "\t\tcontext.write(key, new IntWritable(soma));\n",
    "\t}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-Geração do arquivo JAR da aplicação e definição do path:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo: /home/cloudera/Documents/contapalavraparam.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-Execução do job JAR no ambiente Hadoop, consumo do arquivo bases/base_tw.txt já armazenado no HDFS e passado a palavra \"bigdata\" como parametro  para contagem desta palavra no arquivo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hadoop jar ~/Documents/contapalavraparam.jar ContaPalavraParamDriver bases/base_tw.txt saida/contapalavraparam bigdata"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "SciJava",
   "language": "groovy",
   "name": "scijava"
  },
  "language_info": {
   "codemirror_mode": "groovy",
   "file_extension": "",
   "mimetype": "",
   "name": "scijava",
   "nbconverter_exporter": "",
   "pygments_lexer": "groovy",
   "version": "1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
